## kinesis 시스템 구성하기

**Amazon Kinesis 서비스**

<img src="https://user-images.githubusercontent.com/86764734/150922486-60c9262d-90b2-4d2f-9267-2173e9af103d.png"/>
---

### data-stream 

AWS Console에서 kinesis에 접속한후, 데이터 스트림 생성

<img src="https://user-images.githubusercontent.com/86764734/150922388-5f2913d7-2581-4a87-a0f5-7688bcd9db8a.png"/>

### Firehose 

대시보드에서 delivery stream 선택 후, create delivery stream

<img src="https://user-images.githubusercontent.com/86764734/150923631-c4bc8b57-2c50-46cd-a964-c440c63fba4b.png"/>

#### Source

- Amazon Kinesis Data Stream 
    
    -> 대량의 데이터를 처리하는 파이프라인 구축을 위해 선택한다. 데이터 스트림에 있는 데이터를 컨슈머로 S3에 저장할 것이기 때문!

- direct put(직접 데이터를 받음)

<img src="https://user-images.githubusercontent.com/86764734/150923222-fdcabf8e-b814-48bb-815b-43dbed9ff1e6.png"/>

#### destination

여러 목록 중에 우리가 사용할 S3 선택

- Amazon OpenSearch Service
    
    가장최근에 ~변형해서 만든 서비스

- Amazon Redshift
    
    json형태로 데이터를 다이렉트로 넣을 수 있다.

- Amazon S3
    우리가 사용할 것!

- Datadog
    
    써드파트 서비스로 모니터링 툴이며 데이터를 보낼 수 있다.

- HTTP Endpoint
    
    다른 사이트로 데이터를 보낼 때, http 방식으로 쏴주는 것으로 내부에 발생한 이벤트를 그대로 바로바로 저장해주는 아웃풋방식

<img src="https://user-images.githubusercontent.com/86764734/150924612-cb39b4cb-4649-480b-a31f-57ac59403c91.png"/>

#### source setting

- browse 누르고 아까 생성해준 데이터 스트림인 class-stream 선택 (input)

<img src="https://user-images.githubusercontent.com/86764734/150925092-92912781-820c-4454-93c5-82e2b6c5de91.png"/>

<img src="https://user-images.githubusercontent.com/86764734/150925343-3c498644-840e-4d15-91a6-4ba48a3e139c.png"/>

- delivery stream name 도 데이터 스트림 이름과 동일하게 지정 (firehose 이름)

<img src="https://user-images.githubusercontent.com/86764734/150925412-793f132a-a564-4714-8b5c-511972668ba2.png">

#### Transform and convert records - optional

생긴지 얼마 안된 옵션. enacled를 누르면 람다함수랑 버퍼사이즈를 볼 수 있는데 설정한 버퍼사이즈가 되면 람다가 작동하는 방식

<img src="https://user-images.githubusercontent.com/86764734/151546581-5d46236f-ce63-429f-9757-abf9db9c697e.png"/>

#### Convert record format

**Record format conversion**
glue의 데이터 카탈로그에 테이블을 생성한 다음에 제이슨 방식으로 데이터를 인서트할 수 있는 기능

**Output format**
parquet : 컬럼형태의 포멧을 가지고 있다. 이는 빅데이터를 압축한 형태! 
ORC : 속도는 ORC가 더 좋으나 parquet이 따로 추가적으로  설치안하고 쓸 수 있음

<img src="https://user-images.githubusercontent.com/86764734/151547143-500fa6b4-1ddc-4c1e-9dfe-ffad70f65f88.png"/>

#### Destination settings

- 버킷설정 -> 우리가 이전에 만들어 놓았던 버킷폴더 지정

<img src="https://user-images.githubusercontent.com/86764734/151548008-ef29a7f6-98a2-45b0-b721-8933facfdc6c.png"/>

- S3 bucket prefix - optional → 저장될 위치*

- 버킷폴더 하위에 rawdata/라는 파일 생성
그리고 이벤트가 발생을 하면 Firehose를 통해 이 위치에 저장 한다.

- utc 시간단위 기준으로 쌓이기 때문에 일단위의 데이터를 처리할때 이틀의 데이터를 처리하는 경우가 있을 수 있음

<img src="https://user-images.githubusercontent.com/86764734/151548568-d3c2f7ee-a28d-4085-8315-547345061793.png"/>

#### Advanced settings

<img  src="https://user-images.githubusercontent.com/86764734/151549078-8c2fca24-2a84-44a0-9743-840457bb8da1.png"/>

**Permissions**

- iam 자체를 자동으로 생성해주는  Firehose에서 s3에 데이터를 쓰는거기 때문에 iam 권한을 적용을 해줘야 한다

- 나중엔 iam을 하나 생성해서 하나의 폴터에, 버킷마다 하나의 iam 을 생성해서 거기에 쌓이도록 해야함

<img src="https://user-images.githubusercontent.com/86764734/151549370-5cdbe48d-15ca-402b-a525-40783a74cf83.png"/>

**add new tag**

이름을 구분할때 또는 리소스에 대한 사용을 확인하기 위해 설정해주는 것이 좋다. 태깅을 달아놓고 이 파이프라인에서 발생되는 금액을 확인한다.

#### create delivery stream

<img src="https://user-images.githubusercontent.com/86764734/151549484-a5857ece-9c16-42f6-87a9-288b39f55e65.png"/>

**deliverystream(firehose)가 생성이 되면 정상적인 파이프라인을 구성했다고 볼 수 있다!!**

