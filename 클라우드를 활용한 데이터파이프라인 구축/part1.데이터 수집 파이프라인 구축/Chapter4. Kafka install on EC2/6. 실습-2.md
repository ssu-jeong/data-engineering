#### 간단한 server 띄우기

1. EC2가상머신 연결

```
[~] git(main) ❱❱❱ cd keypair

#연결할 인스턴스 주소
[~/keypair] git(main) ❱❱❱ ssh -i "class-ssu-seoul.pem" ec2-user@ec2-15-164-212-148.ap-northeast-2.compute.amazonaws.com
[ec2-user@ip-172-31-37-201 ~]$ sudo yum update
```

2. 서버 띄울 거기 때문에 http 설치

```
[ec2-user@ip-172-31-37-201 ~]$ sudo yum install httpd -y
[ec2-user@ip-172-31-37-201 ~]$  sudo service httpd start
```

- su - 명령어는 다른 사용자의 계정으로 전환하고 환경변수까지 그 계정의 상태로 완전히 전환

```
[ec2-user@ip-172-31-37-201 ~]$ sudo su -
[root@ip-172-31-37-201 ~]# cd /var/www/html/
[root@ip-172-31-37-201 html]# vi index.html
```
#### kafka server

```
1  sudo yum update
2  java
3  sudo yum install -y java-1.8.0-openjdk-devel.x86_64
4  java -version
5  wget https://dlcdn.apache.org/kafka/3.0.0/kafka_2.13-3.0.0.tgz
6  tar xvf kafka_2.13-3.0.0.tgz
7  ls -al
8  ln -s kafka_2.13-3.0.0 kafka
9  cd kafka
10  pwd
11  ls
12  ./bin/zookeeper-server-start.sh config/zookeeper.properties &
13   ./bin/kafka-server-start.sh config/server.properties &
14  sudo netstat -anp | egrep "9092|2181"
15  bin/kafka-topics.sh --create --topic twitter --partitions 1 --replication-factor 1 --bootstrap-server localhost:9092  &
16  bin/kafka-topics.sh --list --bootstrap-server localhost:9092
17  ./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic twitter --from-beginning
```

#### kafka producer

```
1  sudo yum update
2  sudo yum install -y java-1.8.0-openjdk-devel.x86_64
3  java -version
4  wget https://dlcdn.apache.org/kafka/3.0.0/kafka_2.13-3.0.0.tgz
5  tar xvf kafka_2.13-3.0.0.tgz
6  ln -s kafka_2.13-3.0.0 kafka
7  ls -al
8  cd kafka
9  bin/kafka-console-producer.sh --topic twitter --bootstrap-server 172.31.44.184:9092
10  ifconfig -a
11  wget https://artifacts.elastic.co/downloads/logstash/logstash-7.4.0.tar.gz
12  tar xvzf logstash-7.4.0.tar.gz
13  cd ..
14  wget https://artifacts.elastic.co/downloads/logstash/logstash-7.4.0.tar.gz
15  tar xvzf logstash-7.4.0.tar.gz
16  ln -s logstash-7.4.0 logstash
17  ls -al
18  vi ~/.bash_profile
19  source ~/.bash_profile
20  logstash --version
21  mkdir producer
22  cd producer
23  vi producer_test.conf
24  logstash -f producer_test.conf
25  ls -al
26  cp producer_test.conf producer.conf
27  vi producer.conf
28  logstash -f producer.conf
```

#### kafka consumer

```
[00:07:44] [~] git(main) ❱❱❱ cd keypair
[00:07:47] [cost 0.073s] 591  cd keypair

[00:07:50] [~/keypair] git(main) ❱❱❱ ssh -i "class-ssu-seoul.pem" ec2-user@ec2-13-125-221-35.ap-northeast-2.compute.amazonaws.com
The authenticity of host 'ec2-13-125-221-35.ap-northeast-2.compute.amazonaws.com (13.125.221.35)' can't be established.
ECDSA key fingerprint is SHA256:HZ2YNMWZ01TKoiyRj2xCerXrDcbAcMdJnOyvK4Ry5o8.
Are you sure you want to continue connecting (yes/no/[fingerprint])? yes
Warning: Permanently added 'ec2-13-125-221-35.ap-northeast-2.compute.amazonaws.com,13.125.221.35' (ECDSA) to the list of known hosts.

       __|  __|_  )
       _|  (     /   Amazon Linux 2 AMI
      ___|\___|___|

https://aws.amazon.com/amazon-linux-2/
6 package(s) needed for security, out of 16 available
Run "sudo yum update" to apply all updates.
[ec2-user@ip-172-31-43-53 ~]$ sudo yum update


###그 다음 JAVA 설치
##우리는 아까 인스턴스만들때 넣어줬으니 설치되었는지만 확인
[ec2-user@ip-172-31-43-53 ~]$ java -version
openjdk version "1.8.0_312"
OpenJDK Runtime Environment (build 1.8.0_312-b07)
OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)

##그 다음 logstash설치
[ec2-user@ip-172-31-43-53 ~]$ wget https://artifacts.elastic.co/downloads/logstash/logstash-7.4.0.tar.gz
--2021-12-27 15:12:22--  https://artifacts.elastic.co/downloads/logstash/logstash-7.4.0.tar.gz
Resolving artifacts.elastic.co (artifacts.elastic.co)... 34.120.127.130, 2600:1901:0:1d7::
Connecting to artifacts.elastic.co (artifacts.elastic.co)|34.120.127.130|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 173244608 (165M) [application/x-gzip]
Saving to: ‘logstash-7.4.0.tar.gz’

100%[===================================================================================================================>] 173,244,608 50.2MB/s   in 3.5s

2021-12-27 15:12:26 (47.3 MB/s) - ‘logstash-7.4.0.tar.gz’ saved [173244608/173244608]

##압축해제
[ec2-user@ip-172-31-43-53 ~]$ tar xvzf logstash-7.4.0.tar.gz

##링크를 걸어서 나중에 버전이 바뀌어도 환경에 영향을 안받게
[ec2-user@ip-172-31-43-53 ~]$ ln -s logstash-7.4.0 logstash

##그 다음 path를 넣어준다 - 초기화 파일에 추가. : 어느 폴더에서도 logstash 실행가능
[ec2-user@ip-172-31-43-53 ~]$ vi ~/.bash_profile
# .bash_profile

# Get the aliases and functions
if [ -f ~/.bashrc ]; then
        . ~/.bashrc
fi

# User specific environment and startup programs

PATH=$PATH:$HOME/.local/bin:$HOME/bin
# 여기 사이에다가
export LS_HOME=/home/ec2-user/logstash
PATH=$PATH:$LS_HOME/bin
export PATH
~
~
~
~
~
~
~
~
~
# i 누르면 수정가능하고 ctl+c 누른 후 :wq 입력하면 빠져나올 수 있다.

# source명령으로 환경 실행
[ec2-user@ip-172-31-43-53 ~]$ source ~/.bash_profile

# 잘 설치 됐는지 확인
[ec2-user@ip-172-31-43-53 ~]$ logstash --version
logstash 7.4.0

"""
producer와 consumer의 수는 다를 수 있다.
그래서 consumer sever는 여러개를 구성해서 각각 목적에 맞게, 
필요한 부서에서 가져가서 사용 가능
"""

# consumer 폴더 만들기
[ec2-user@ip-172-31-43-53 ~]$ mkdir consumer
[ec2-user@ip-172-31-43-53 ~]$ cd consumer

"""
서버에 있는 데이터를 받아서 화면에 출력
출력해서 db에 넣을 수도 있고,
S3에 copy해서 넣을 수도 있고
등등의 기타 작업을 수행할 수 있다.
"""

"""
콘솔상에다가 프린트 아웃하는것 까지가 목표
트위터에서 데이터를 가져와서 producing해서
kafka의 큐에다 넣고 
큐에 있는 데이터를 consumer 서버를 하나 띄워서
consuming 하는 흐름
"""
[ec2-user@ip-172-31-43-53 consumer]$ vi consumer.conf
#i 입력하고 들어가서 아래 내용 입력! 서버 나의 ip주로소 변경!

input {
  kafka {
    bootstrap_servers => "172.31.15.105:9092" # 서버정보
    topics => ["twitter"]
    consumer_threads => 1
    decorate_events => true
    }
}

output {
stdout {
codec=> rubydebug
}
}
#실행을 하면 이제 얘가 consumer가 된것!
[ec2-user@ip-172-31-43-53 consumer]$ logstash -f consumer.conf

# 그 후 producer 서버에서 아래 코드 실행하면 트위터 데이터를 kafka 서버로 보낸다
[ec2-user@ip-172-31-47-24 producer]$ logstash -f producer.conf


"""
클러스터:
많은 데이터를 처리할 떄 리소스가 많이 들어가기 떄문에 그걸 분산시켜서 처리하는 방법
"""

"""
근데 실습과정에서 오류가 생김!
consumer에서 데이터를 프린트아웃하지 않고, kafka 서버에서 확인됨... 이유가 뭘까? -> 다시 실행하여서 오류 원인에 대한 추가 정리 필요
"""
```

