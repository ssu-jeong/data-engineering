## EMR환경에서 Pyspark 실습

---

이번시간에는 emr에서 pyspark 실습! 
최근에 pyspark이나 파이썬을 통해서 분석하는 상황이 많다.

그래서 분석가가 그런 환경에서 분석하기 위해서  어떻게 구성하면 되는지 실습진행.

많이 사용하는 jupyterlab을 사용하고 전에 실습했던 기본적인 여러 타입의 데이터를 읽어서 쓰는 그런 실습을 진행할 것!

### NOTE BOOK

왼쪽 메뉴탭에 보면 노트북이라는 것이 있다. 

노트북이 의미하는 바는 쉽게 얘기해서 에디터만 띄어줄 수 있는 환경을 구성하는 것이라 생각하면 된다. 

노트북에서는 에디터환경하고 거기에서 생성된 그 소스코드를 저장하는 것. 그 두가지 포인트로 구성한 서비스라고 생각하면 된다. 

그래서 우리가 이 노트북에서 emr클러스터를 연동해서 사용해볼 것.

![3-1](https://user-images.githubusercontent.com/86764734/162759772-d668fa0c-7eb0-4392-b6cb-81fa5c7c41de.png)


### EMR

1. 클러스터생성

    - 고급옵션으로 이동

    ![3-2](https://user-images.githubusercontent.com/86764734/162759783-d4f81c24-ac5a-47fb-9cce-01ac64a05d25.png)


    - 소프트웨어구성

        - Livy: 어플리케이션간의 인터렉티브. 어떤 서비스에서 spark에 어떤 job을 던지기 위한 어플리케이션

        - 쥬피터추가: 우리가 에디터는 쥬피터노트북을 사용할 것이기 때문에 제플린은 디져브

        - spark

        ![3-3](https://user-images.githubusercontent.com/86764734/162759794-1331fd8c-56cc-4f02-958a-900e606344dd.png)


    - 카탈로그

    ![3-4](https://user-images.githubusercontent.com/86764734/162759819-0aa3bff4-c3ec-458f-95f1-4ac431e68c29.png)


    - 클러스터 노드 와 인스턴스
        
        - 여기서 중요한 기능이 추가되었다. 과거에는 클러스터를 구성하기 위해서 적어도 마스터와 코어노드 두개는 무조건 있었어야 했는데 최근 업그레이드 된 버전에서는 코어노드를 0으로 하고 해도 된다. 이번에는 하나만 띄우기 때문에 온디멘드로 진행.
        
        - 그럼 EC2서브넷은 설정하지 않아도 되는부분???

    ![3-5](https://user-images.githubusercontent.com/86764734/162759836-f57c8c14-45f3-41a1-a37d-7f0460baa7fb.png)


    - 일반옵션
    
    클러스터 이름과 태그를 달아주자
    
       - 태그 
        → 이름을 달아줘야 ec2에 떠있는 인스턴스중에서 찾을 수 있기 때문에

    ![3-6](https://user-images.githubusercontent.com/86764734/162759848-c2e20792-d6f1-4a8a-adb1-4a1873171146.png)


    - 보안
        - 키 페어: 우리가 이전에 생성해두었던 키페어 선택해주면 된다.

    ![3-7](https://user-images.githubusercontent.com/86764734/162759862-c15fb3fa-b16a-4252-a7e5-965ab512d161.png)


    - 클러스터 생성
    
    이렇게 되면 프로비저닝을 통해서 클러스터가 뜰 것.

    ![3-8](https://user-images.githubusercontent.com/86764734/162759872-39e28efe-a8f8-4281-b2d7-4e8deb09e780.png)


    - 구성세부정보
    
    우리가 띄워놓은 어플리케이션이 보인다.

    ![3-9](https://user-images.githubusercontent.com/86764734/162759878-09866969-c52a-46f8-a7de-73dc87f1c455.png)


    여기는 쉽게말해 컴퓨팅만 지원을 해줄 것!

### 노트북 생성

노트북에서는 에디터와 이 에디터로 생성된 소스에대한 관리만 할 것이다.

1. 노트북 생성

![3-10](https://user-images.githubusercontent.com/86764734/162759893-3cb9c785-68f2-4499-aefe-435570021597.png)


2. 노트북 이름 지정 및 구성
    
    이 노트북은 항상 켜있는 것이 아니라 꺼져있다가 켜졌다가를 반복할 수 있다. 
    
    여기서 직접 클러스터를 생성할 수 도 있다. 그러나 직접 생성하니까 잘 안되는 부분들이 있고 생성되는 시간이 있어서 먼저 클러스터를 생성하고 구성하는 것이 좋다. 
    
    - 이름

    ![3-12](https://user-images.githubusercontent.com/86764734/162759900-24b33347-2272-4fce-9684-3639b60b5737.png)


    - 클러스터

        - 기존클러스터 선택
            
            아까 만든 리비와 주피터노트북을 같이 띄운 대기중인 클러스터를 선택

            ![3-13](https://user-images.githubusercontent.com/86764734/162759913-817b0e59-f405-4a78-9f75-9f14ab75d936.png)


    - 노트북위치

        - 노트북의 역할 중에 소스코드 저장이라는 역할이 있다. 개인이 만약에 이런 노트북을 구성한다면 본인이 작성한 노트북을 계속 s3에 저장할 수 있는 기능이 있다.(자기 폴터 혹은 팀의 폴더를 만들어 소스를 저장할 수 있게)

    - git 레포지토리

        - 깃 같은 경우에도 연동을 해서 git에 소스코드를 저장할 수 있다. git을 통해서 하면 평생관리도 가능하기 때문에 git을 통해서 하는 게 더 좋고 용도별로 s3에 저장하는 것도 나쁘지 않다.

    - 노트북 생성완료

        - 시작이 되면 이런 워크스페이스가 생성이 될 것이다.

        - 워크스페이스가 생성이 되면, jupyterLab에서 열기 버튼이 활성화 될 것이다.

        ![3-14](https://user-images.githubusercontent.com/86764734/162759932-4832ce18-0af9-4999-a23d-72b4e3a67597.png)


최근들어서 파이썬이 많이 사용하다 보니까 pyspark에 대한 사용자가 많아졌다. 그래서 전체적 환경을 제공해주는 주피터랩을 많이 사용하기 때문에 우리가 분석가에게 연동을 해서 제공을 해주면 분석가분들이 쉽게 할 수 있다.

### JupyterLab

지금 보면 노트북이 하나 생성되어 있는 것이 확인된다. 

오른쪽에는 쓸 수 있는 환경들을 제공을 해준다. 

우리가 할 것은 파이썬은 아니고 pyspark.

![3-15](https://user-images.githubusercontent.com/86764734/162981562-eb1c3e40-62b5-45fb-a773-6e629965c644.png)

1. 사용 할 환경 선택
    
    pyspark 선택

    ![3-16](https://user-images.githubusercontent.com/86764734/162981576-f9a7d7df-cf84-49fa-9dda-1a5ca5684ee1.png)


    ![3-17](https://user-images.githubusercontent.com/86764734/162981594-ade2438e-feee-41a7-85d3-76199e5b8bd3.png)


2. 제공된 소스코드 올려보기

![3-18](https://user-images.githubusercontent.com/86764734/162981610-f06296e4-72a9-4331-90e3-bc6f7a53aee7.png)


6.2 소스코드 선택 이거는 지금 3.2를 가지고 조금 변경한 소스코드!

scalar에서 또 pyspark으로 변경이 많은 부분이 변경하는 부분이 없어서 쉽게 할 수 가 있다.

![3-19](https://user-images.githubusercontent.com/86764734/162981617-02b328bb-a27e-4dae-8c35-bb042a46571e.png)


그래서 그 부분을 더블클릭하면 열린다.

![3-20](https://user-images.githubusercontent.com/86764734/162981637-8cf3bb54-1640-4cb5-8434-76a0f05ff2d4.png)


3. 소스코드 확인

    a. spark context 초기화
        
        spark연동관련해서 실행해주는.
        
        버킷을 변수처리해줌! 버켓이름만 확인해서 변경해주면 된다. 
        
        초기에는 얘가 spark와 세션을 연결하기 위해서 계속 도는 부분이 있기 때문에 조금 시간이 걸린다. 
        
        spark와 세션이 연결이 되면 좀 빨라지겠죠?

    ![3-21](https://user-images.githubusercontent.com/86764734/162981658-ccf4c195-12b6-4cfd-bae1-734ad71f8b89.png)


    b. File Read
    
        여러 타입의 데이터를 읽고 그것을 쓰는 실습.
    
        요거를 잘 이용해서 병행하면 가지고 있는 여러 소스들을 가지고 우리가 컨버팅 할 수 있다고 생각한다.

    ![3-22](https://user-images.githubusercontent.com/86764734/162981675-65ebec8f-1f8f-4730-a580-cd1bf574f88b.png)


        스칼라 문법하고 pyspark문법이 거의 비슷하다. 우리가 접근하기 그렇게 어렵지 않다. 

    ![3-23](https://user-images.githubusercontent.com/86764734/162981713-50595f44-0b75-48fa-8714-b8ecf6264652.png)

        최근에는 파이썬에서 이것을 다시 spark의 형태의 데이터 프레임으로 변경하는 기능들이 생겨나서 그런것들을 잘 이용한다면 큰 데이터를 처리해서 spark의 데이터 프레임을  파이썬의 pandas형태로 만들 수 있다. 왜? pyspark자체가 디스트리뷰트 하기 때문에 많은 데이터를 가지고 분석을 한다고 하면 10기가의 데이터를 1기가의 파일로 줄인 pandas 파일로 만든 다음에 머신러닝쪽으로 적용을 한다면 좀 더 빠르게 적용할 수 있을 것.

        아무래도 큰 파일을 핸들링하는 것은 spark 자체가 조 ㅁ더 장점이기 때문에 파일이 클경우에으 될 수 있으면 spark르 사용하는 것이좋다. 파일의 크기가 작을 경우는 파이썬이 좀 빠르다 왜? 하나의 노드에서 하기 때문에 즉, 노드가 어떤 통신도 없기 때문에.
        하지만 데이터량이 커진다고 하면 spark가 훨씬 더 빨라진다. 파이썬 같은 경우는 그런 작은 파일을 처리하기가 힘들다.

        c. pyspark 자체도 템포러리 뷰를 만들 수 있다. 그래서 danji라는 테이블을 만든 다음에 확인작업이 가능

    ![3-24](https://user-images.githubusercontent.com/86764734/162981727-226fcc25-452c-4bca-a599-da2b1f53e3bd.png)


    ![3-25](https://user-images.githubusercontent.com/86764734/162981742-dc310f46-1aba-4a51-9d1d-c89f498f406b.png)


        d. 테이블 통해서 조회도 가능 

    ![3-26](https://user-images.githubusercontent.com/86764734/162981756-6fa4e0a9-5e6d-4964-b4c7-2ad11e304fe1.png)


        e. 스칼라문법하고 다른점은 %%sql 하면 sql을 날릴 수 있는 환경을 제공한다.

    ![3-27](https://user-images.githubusercontent.com/86764734/162981773-4c3860ae-fb51-462a-a1f9-58ae18f50730.png)


4. DB 읽기
    
    클러스터에다가 드라이버를 설치하거나 두개가 연결할 수 있는 세셥에다 하면 되는데 그건 좀 어렵고. 
    이전에 클러스터에다가 드라이버를 설치하는 쉘을 하나 만들어 놨기 때문에 그대로 이용.
    
    -> 이럴 경우에는 우리가 띄운 클러스터에 들어가서 단계!

    - 단계 추가

        - wget을 통해서 리모트에 있는 사이트의 드라이버를 다운받아서 그 드라이버를 하둡에 spark에 jar에 드라이버를 설치하는 스크립으로 설치.
        주피터랩으로 실습을 할건데 이게 바로 적용이 안된다. 드라이버를 나중에 추가한거기 때문에

        ![3-28](https://user-images.githubusercontent.com/86764734/162981792-c38af911-f586-4ae6-b146-a93187c5935f.png)


        - 추가가 완료될때까지 기다리고 새로고침

    - 기존에 세션서는 jdbc드라이버에 드라이버가 없었다.  그래서 mysql을 접속하는 ..그러기 때문에  그럴 경우에는 커널을 재기동
    
    ![3-29](https://user-images.githubusercontent.com/86764734/162981816-e9bdad29-96fe-413a-b8a3-3d0aec9aa45c.png)


    - 그다음에 다시 컨넥션을 해아한다.

        - spark context 초기화 셀 다시 시작 이렇게 해줘야 이 드라이버가 적용이 된다.

    - 띄워놓은 mysql의 엔드포인트를 변경해주자
        - hostname: 엔드포인트
        - databast: “dm”
        - username: “admin”
        - password: “ “

        ![3-30](https://user-images.githubusercontent.com/86764734/162981843-a6d4e26b-f260-4816-87de-c15d8adf2e3c.png)

        에러가 난다...테이블 이름 오류로 수정해서 다시 실행하자

        ![3-31](https://user-images.githubusercontent.com/86764734/162981868-df671394-5dae-4b6b-bb08-1ae857663baa.png)

        드라이버 설치하는 부분도 예전 처럼 쉘로 들어가서 작업하는게 아니라 될 수 있으면 emr이 가지고 있는 그런 기능들을 활용하고 자동화하면 그게 나중에 데이터옵스 ml옵스를 할 수 있는 것.

    - 현재 pyspark에 있는 데이터와 s3에 있는 데이터를 연동해서 분석을 한다던지 그런 부분도 pyspark에서 자유롭게 분석할 수있다. 
    이런 환경일 경우에 우리가 노트북일 경우에는 이 소스코드를 어디에 저장된다? s3에 저장된다. 확인해보자

5. 소스코드 저장확인.
    
    여기보면 노트북이 저장되있는 것을 확인 할 수 있다.

    ![3-32](https://user-images.githubusercontent.com/86764734/162981886-febf41df-a461-4112-a4e5-2e2cfb058927.png)


    자동으로 저장되어 있기 때문에 이 노트북 클러스터가 꺼져도 삭제가 되도 소스코드가 남아있기 때문에 나중에 다시 노트북을 생성을 하면 소스코드를 가져와서 작업할 수 잇는 그런 환경이 된다. 

    ![3-33](https://user-images.githubusercontent.com/86764734/162981977-698a0883-e96d-4ca4-b530-afc1d4a377aa.png)


    항상 강조를 하지만 클라우드이기 때문에 어떤 컴퓨팅 관련된 노드나 리소스를 켜서 작업하는 것들을 계속 배제해 나가야한다. 
    그럴 경우에는 이제 노트북만 사용하고 클러스터를 끌 수 있기 때문에 서로 독립적이라서 이런 아키텍쳐를 좀 더 확장할 수 있는 개념들을 우리가 확장시켜갈 수 있다. 












