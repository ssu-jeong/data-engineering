### AWS Glue

---

과거에 데이터 파이프라인이라는 서비스가 있었는데 그 부분의 단점을 보완해서 나온 서비스.

ETL 워크플로우를 정의하고 job을 돌릴 수 있다.

#### 대표적인 3가지 기능

- Data Catalog
    
    - AWS Glue 데이터 카탈로그는 영구적 Meta Data Store 이다.
    
    - 카탈로그는 과거에 하둡시스텝을 사용할때 메타데이터스토어라고 생각하면 된다. 그냥 일반 온프라미스같은 경우도 메타 시스템이 있었다. 
        
        - 이 데이타카달로그가 가지고 있는 의미에대해서 생각해 볼 필요가 있다.
    
    - 가격은 좀 싼 서비스!

- AWS Glue Crawlers

    - 레포지토리에서 데이터를 스캔하고 분류, 스키마 정보를 추출 및 AWS Glue Data Catalog에서 자동적으로 Metadata를 저장하는 Crawlers를 설정할 수 있다.
   
    - S3라는 스토리지에 저장되어 있는 sql이라는 데이터분석용 툴로 분석을 한다라는 의미를 조금 더 이해하기 위해서 크롤러 실습을 진행
    
    - 대부분 sql을 사용한다는 것은 dbms가 설치가 되어 있어야하고 거기에 클라이언트를 깔아야하고 이러한 환경에서만 대부분 sql로 분석을 해왔기 때문에 크롤러에 대한 실습을 진행

- AWS Glue ETL 연산

    - AWS Glue Jobs System

        - 잡에 대해서 최근에는 스트림서비스에 대해서 분석할 수 있는 환경 제공
    
    - Trigger 기능

### AWS Glue Data Catalog : Data Store

---

좌측에 보면 데이터에 대한 레포지토리 즉 스토어에 대한 여러가지 기능, 서비스가 있다. 데이터를 저장하고 있는 레포지토리 기능을 볼 수 있다. 

그리고 최근들어 여러서비스들이 추가가 되었다. 이런 서비스들의 데이터 저장형태를 관리하기 위해 있는 것이 데이터카탈로그 기능!

데이터카탈로그기능에서 이제 데이터 스토어에 있는 메타정보, 데이터가 어떻게 저장되어 있는지에 대한 기능들을 데이터 카탈로그에 저장을 하는 것. 그렇게 되면 사용자가 어떤 데이터가 어디에 저장 되어있고 어떻게 저장되어 있는 확인이 쉽다. 특히 테이블 같은 경우에 테이들의 어떤 항목 또는 컬럼(속성) 사실 메타에선 항목이라는 단어를 많이 씀. 그런 내용들을 이 데이타 그루의 데이타카탈로그에 저장하고 관리를 하면 남의 데이터를 확인하거나 크롤러에 의해서 불러온 메타 데이터를 호가인할 수 있는 기능으로 보시면 된다. 

가장 중요한게 (메타데이터) 데이터 카탈로그에 저장이 되어 있으면 AWS의 대표 서비스인 아테나나 데르시프트의 스펙트럼, 아마존의 이엠알을 통해서 분석을 쉽게 할 수 있다. 

아테나 같은 경우 서버리스 서비스로 평소에는 사용하지 않고 있다가 분석이 필요하면 아테나의 서비스를 켜고 분서긍ㄹ 할 수 있다.

레드시프트는 올드데이터 혹은 데이터마트 관련된 데이터를 관리할 수 있는 dbms라고 볼 수 있는데, 거기서 더 디테일한 데이터를 분석할 수 있는 기능인 스펙트럼을 사용해서 s3에 저장되어 있는 데이터를 분석할 수 있다.

아마존 이엠알은 하둡환경으로 카탈로그에 저장되어 있는 것을 쉽게 스파크의 sql을 통해 쉽게 접근하여 분석할 수 있다. 

그외에 최근에 글루에서도 jod etl을 돌릴때 데이터에 쉽게 접근할 수 있는 기능을 데이터 카탈로그에 저장해놓아서 사용할 수 있다. 

이러한 방법을 사용해야 분석쪽에서도 다양한 방법으로 분석을 할 수가 있기 떄문에 사용을 권장!

![4-2-1](https://user-images.githubusercontent.com/86764734/155843687-c8c35404-978f-40a7-8aca-f15429de54ae.png)

### AWS Glue Crawlers

초기에는 크롤러 기능이 s3에 있는 데이터를 쉽게 분석할 수있어 좋은 기능이었으나 최근에는 S3내에서도 sql로 간단하게 분석할 수 있는 기능들이 추가 되면서 사용을 많이 하는 편이 아닐 수도 있다. 

S3에 저장되어 있는  데이터를 spark sql로 분석할 수 있는 3가지 여러 기능에서 분석할 수 있다. 어떤 플로우로 분석할 수 있는지를 좀 이해해보자!

즉, S3에 있는 데이터를 글루의 크롤러 기능을 활용해서 데이터 카탈로그에 데이터 정보를 저장을 하고 저장된 정보를 Athena나 EMR Redshift의 스펙트럼을 통해서 접근이 가능하다라는 것을 확인 해보도록 할 것.

이번 실습에서는 emr이나 아테나 쪽에서 실습을 진행할 것이고 redshift는 차후에 stectrum 등 기능이 가지고 있는 의미를 실습 할 예정

![4-2-2](https://user-images.githubusercontent.com/86764734/155843709-5c462ebe-cf34-4e89-9e08-a3fca8559102.png)

크롤러는 redshift나 s3 rds등 여러가지 dbms,  s3에 접근할 때는 서비스와 서비스 사이에 IAM을 생성을 해서 IAM을 통해 접근을 한다. 

Glue의 크롤러에서 s3에 접근하기 위해서는 IAM을 하나 생성을 하고 s3에 접근하여 저장되어 있는 오브젝트 값(오브젝트 스토리지에 저장되어 있는 파일 → 여러 메타값과 버전 등 포함) 이런 속성값을 활용해서 분석할 수 있는 테이블 형태로 변형하는 작업을 진행하고 Glue의 데이터카탈로그에 저장하는 기능을 glue의 크롤러가 진행한다. 

rds와 redshift등에 있는 메타값은 jdbc를 통해서 가져올수가 있다. 그래서 Glue에서 메타값을 가져올 수 있다. 근데 오른쪽에 나와있는 서비스에서 활용할 수 있는 것은 jdbc를 통했을땐 단지 메타값만 가져올 것이고, S3에 저장된 값은 직접적으로 쿼리가 가능하다.

![4-2-3](https://user-images.githubusercontent.com/86764734/155843741-0cdd1e89-70c4-4ea8-9e1e-c0951b83f8f0.png)