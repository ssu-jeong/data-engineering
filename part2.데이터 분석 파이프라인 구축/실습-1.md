## EMR 실행

---

### 클러스터 생성
-  먼저 aws콘솔창에서 ERM 검색.

- 기본적으로 설정된 값들이 있으나, 고급옵션으로 이동하여 생성. 그래야 비용을 아낄 수 있도록 설정 가능!!

![emr1](https://user-images.githubusercontent.com/86764734/152645310-eff41cfc-e2ba-4a7c-b423-6264052a0d66.png)

### 단계1, 소프트웨어 구성

![emr2](https://user-images.githubusercontent.com/86764734/152645521-57a2b05d-9291-490a-8f26-5da84f3a1134.png)

- 소프트웨어: Hadoop(하드웨어)에서 돌아갈 수 있는 여러 시스템(어플리케이션들)
우리가 이걸 직접 설치진행하면 하나하나 잘 작동되는지 확인 해야 하지만, aws를 이용하면 관리형 클러스터로서 우리가 깔고 싶은 여러가지를 에코시스템에서 제공해준다. 

- emr 릴리스: 거기에 맞게끔 구성된 부분을 어떤 버전에 맞게 계속 생성된것. 

5버전은 현재 관리형관련해서 올라간 부분. 6버전은 도커를 함께 실행할 수 있는 버전 

- 추가적으로 ganglia, zeppelin, 엔진은 spark엔진 사용 그리고 Hue는 디절브

- Zeppelin: 웹환경에서 spark에 여러가지 커멘드 프로그램을 짜서 스파크에 잡을 던진다고 보면 우리가 어플리케이션 간에 잡을 주거니받거니 할 수 있도록 하는게 리비 이다. 

#### 마스터노드


#### Glue

![emr3](https://user-images.githubusercontent.com/86764734/152645690-5a1628c1-df4e-45c0-b4c2-43f647255737.png)

- glue에 있는 데이터 카탈로그(메타정보)가 우리가 테이블로 구성하면 S3로 저장하게 된다.(그 정보를 관리하는 툴이 데이터 카탈로그)

- 거기에 있는 정보를 쓸거다(해당 데이터카탈로그를 사용)하면 둘다 체크! -> 우리는 기본적으로 메타스토리지를 glue에 있는 것을 쓸거기 때문에 둘다 체크

### 단계2, 하드웨어 구성

#### 클러스터 컴포지션

![emr4](https://user-images.githubusercontent.com/86764734/152645952-9e309be6-04ff-4719-ae0a-b5c0d0625107.png)

#### 네트워크 

![emr5](https://user-images.githubusercontent.com/86764734/152645995-d5a13126-0d2e-42d8-92bc-b89ec5956053.png)
- vpc는 하나의 건물이고 서브넷은 각 층이라고 생각하면 된다. 

- 기본값으로 설정할 경우 서브넷 a,b,c,d 네가지 존에 각각 서버가 위치할 수 있게 구성할 수있다. 

#### 클러스터 노드와 인스턴스

![emr6](https://user-images.githubusercontent.com/86764734/152646051-a1f8000d-8252-4d06-9fce-7b93c5179e11.png)

- 클러스터: 사용자는 하나의 컴퓨팅처럼 사용하지만 밑단에는 여러 서버들로 연결되어 있다. 이 각각서버들을 노드라고 함. 그 노드로 구성된 것이 클러스터

- 거기에 맞는 노드유형을 인스턴스에 설정해주면 된다. 

  - 마스터노드 → 1개로 구성 지시자는 1명이여야해서!

**인스턴스유형**

![emr7](https://user-images.githubusercontent.com/86764734/152646236-1dd7f5e9-c741-4f51-842e-4c37f877976c.png)


- 기본적으로 r3.xlarge 

- 보통 spark는 메모리 베이스로 데이터를 분석하는 툴.
그래서 인스턴스 유형중에 메모리의 유형에 강한 r타입 인스턴스 유형을 사용! (i: io,g: gpu,c: computing)

- 워커노드는 될 수 있으면 모두 더했을 때 홀수! → 잡을 수행 할때 경쟁이 생기지 않게 하려면 보통 홀수가 좋다고 한다.

**구매옵션**

![emr8](https://user-images.githubusercontent.com/86764734/152646366-4e2db519-32d6-4b00-9dd6-a10c4d98e063.png)

- 온디맨드: ec2를 그냉 구매해서 사용하는 형태
- 스팟: 유효장비. 각 존에 남아있는 유효장비를 사용하고자 하는 고객들한테 비딩을 붙여서 사용하게 하는 그래서 70-90퍼로 저렴하게 aws에서 사용가능하게 제공한다. 

  - 그래서 많은 양의 데이터를 분석할때는 이렇게 엘러스틱한 분석에 가장 효과가 좋은 스팟을 사용하면 저렴하게 분석가능  
  
  - 그래서 우리는 스팟을 선택!!

- 초록색은 스팟 인스턴스 제공가능, 하얀색은 제공불가 → 이게 서브넷을 변경 해줘야 하는 경우가 생길 수 있는 것! 사용 가능한 것을 확인해서 서브넷을 설정해줘야한다.

- 온디맨드 같은 경우는 사용하는 사람이 많으면 가격이 변동

![emr9](https://user-images.githubusercontent.com/86764734/152646474-e4e5b5ff-121f-47c6-adbc-973c26422e25.png)

- 온디멘드 가격까지 올라갈때까지 스팟 인스턴스가 죽지 않는다. 

이렇게 구성하면 거의 죽는경우가 없다. 죽지않게 구성할려면 마스터와 코어를 온디맨드로 하면 되는데, 우리는 컴퓨팅과 스토리지를 분리하였기 때문에 분석하다가 죽어도 데이터의 유실이 없기 때문에 스팟 인스턴스로 사용해도 크게 무방

### 단계3, 일반 클러스터 설정

#### 일반 옵션

![emr10](https://user-images.githubusercontent.com/86764734/152646546-b43b340f-0738-4ee3-b5b5-3c8d8c473653.png)

- class-master → 클러스터 이름 설정 

- 로깅폴더 → 이 클러스터가 돌때 어떤 에러가 나면 그 에러들을 s3폴터에 로그를 떨궈준다. 

- 클러스터 이름을 복사해서 태그 네임 설정 

- 부스트랩은 나중에 설명 그리고 다음을 누른다.

![emr11](https://user-images.githubusercontent.com/86764734/152646593-3f354f85-861d-4bb8-9139-77d768403bf6.png)

### 단계4, 보안

![emr12](https://user-images.githubusercontent.com/86764734/152646662-f32f9333-0179-4987-bcaa-b89db0a63f52.png)