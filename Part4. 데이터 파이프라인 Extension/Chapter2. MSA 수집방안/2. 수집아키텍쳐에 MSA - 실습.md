## 수집아키텍쳐에 MSA - 실습

---

데이터 수집을 위해서 api-gateway에서 외부로 부터 오는 데이터를 수집을 했다. api-gateway로 가서 msa처럼 쉽게 확장할 수 있는 그런 그 기존에 울기ㅏ 구성했던 api-gateway를 보고 확장을 해보자. 

### Api-Gateway

---

#### 1. 리소스 생성

![2-2-1](https://user-images.githubusercontent.com/86764734/161387610-1509efe2-a9cc-4d8e-9936-e2d85745d1c0.png)

우리가 기존에 v1이라는 버전의 gateway를 만들었다.

![2-2-2](https://user-images.githubusercontent.com/86764734/161387621-8301f761-539f-4f38-8680-64ed3630e406.png)

그래서 이번엔 확장된 개념이기 때문에 v2라는 버전을 생성해보도록 할 것.

![2-3](https://user-images.githubusercontent.com/86764734/161387631-74fe54f9-0476-46a6-9a8a-22fcad633fa0.png)

리소스 생성에서 v2 생성

![2-4](https://user-images.githubusercontent.com/86764734/161387640-158ad078-9a17-43c6-bcd7-4619ea656bea.png)

그 다음에 리소스를 변수처리를 해줘야 하는데, 변수를 추가하기 위한 방법. 

![2-2-5](https://user-images.githubusercontent.com/86764734/161387656-d2b2e1c4-057f-4e6e-9309-291eb8bb32a9.png)

그리고 중괄호 해서 파라미터 처리를 해준 후, 그런 다음에 리소스 생성

![2-2-6](https://user-images.githubusercontent.com/86764734/161387662-f97442d3-00ca-4956-9336-c9177a06e7f9.png)

![2-2-7](https://user-images.githubusercontent.com/86764734/161387671-6f514145-202f-47f5-b764-e6b98841f385.png)

그 다음에 우리가 이전에 했던 작업과 똑같이 진행하면 된다. (-> POST라는 메소드에 따라 태스크를 처리)

#### 2. 매서드생성

작업에서 매서드 생성→ post → 체크를 눌러주면 어떤 서비스를 쓸건지 설정하는 화면이 나온다. 

우리가 사용할 서비스는 kinesis stream이기 때문에 aws서비스를 선택

![2-2-8](https://user-images.githubusercontent.com/86764734/161562412-1aec4647-f2a6-4df6-8179-7b162a30c37d.png)

실행역할 → api-gateway에서 kinesis stream에 대이터를 쓰거나 읽을 수 있는 권한.

우리가 이전에 생성해 놓은게 있으니 찾아보자

IAM으로 가서

![2-2-9](https://user-images.githubusercontent.com/86764734/161562463-6cddc615-45c0-493e-af29-09b698dc0686.png)

주소 복사

![2-2-10](https://user-images.githubusercontent.com/86764734/161563897-5712ca32-b96d-401a-9450-fbba431fbb32.png)

복사된 주소를 넣어주면 된다 → 저장

![2-2-11](https://user-images.githubusercontent.com/86764734/161563948-4bd87578-ff91-41f0-ac0d-b717d86e1d6e.png)

그렇게 되면 전체적인 플로우를 보여줄 것 

![2-2-12](https://user-images.githubusercontent.com/86764734/161563984-fb9dd879-5361-490a-9591-df30d771c425.png)

#### 3. 통합요청

들어온 데이터를 어떻게 변환할 건지를 통합요청에서 작업을 진행

![2-2-13](https://user-images.githubusercontent.com/86764734/161564029-ef43dda3-2661-49df-b31b-24469926fdd7.png)

통합요청으로 가서 

![2-2-14](https://user-images.githubusercontent.com/86764734/161564062-9a6e4ce1-a034-4366-b506-bdf0145a659d.png)

- HTTP 헤더

    - 들어온 http의 헤더값을 정의 

    - 이름은 컨텍트 타입

    - 컨텍트 타입은 아마존에서 정의한 json 형태 → 꼭 저장해주자

    ![2-2-15](https://user-images.githubusercontent.com/86764734/161564114-f3b3045e-c9da-45f8-a29d-c8a67b0f839b.png)

- 매핑 템플릿

    - 바디에 해당하는 것.

    - 매핑템플릿 추가 누르고 타입 → 저장

    ![2-2-16](https://user-images.githubusercontent.com/86764734/161564135-438642fe-90f2-4f3a-8d2f-cae88976cd87.png)

    - 저장을 해주면 에디터창이 나온다. 

    - 스크립에 제공된 내용을 카피해서 붙여넣으면 된다. 만약에 했는데 잘 안되면?

    - 앞에 스페이스를 안넣은 것은 특수기호나 다른 기호가 들어가면 에러나는 경우가 있기 때문에

    - 설명

        - 엔터값이고, 현재 엔터값을 붙인 입력값을 받아서 kinesis로 던질 수 있는 데이터 형태를 만드는 것.

        - 그래서 데이터 형태는 베이스 64로 인코딩한다 왜? 들어온 데이타 중에서 특수문자가 있는 경우 오작동할 수 있어서

        - 파티션 키는 shard를 여러개 운영할 경우에 그 shard가 병렬로 처리하기 때문에 하나의 앞뒤 순서에 맞게 끔 데이터를 구성하기 위해서 넣어준다.

        - stream name 부분에 우리가 아까 리소스에서 하나의 변수로 처리한다고 정의했다. 그 부분을 파라미터값으로 해서 변수병으로 stream name을 받겠다.

        - 이전에는 스트림명을 그대로 넣었었다. 스트림을 먼저 생성하고 스트림명을 넣었는데 변수명을 처리함으로써 나중에는 data stream하고 firehose 그리고 s3에 폴더를 한다면 서비스 별로 데이터를 s3에 저장할 수 있는 파이프라인을 쉽게 구성할 수 있을 것.

        - 이제 저장하기

        ![2-2-17](https://user-images.githubusercontent.com/86764734/161564187-31472a64-a185-4997-a0ef-49083f622e1a.png)

- API 배포

    - PROD에 배포

![2-2-18](https://user-images.githubusercontent.com/86764734/161564249-4ad67eda-8f12-4562-8466-86d773d1d5d0.png)

![2-2-19](https://user-images.githubusercontent.com/86764734/161564297-08e6afdd-e908-46c1-9526-e4992a3646d8.png)

#### 4. 스테이지

- PROD 스테이지 편집기

![2-2-20](https://user-images.githubusercontent.com/86764734/161564346-0179bca2-3772-451e-8401-ef19caf3ecd6.png)

- post를 클릭해보면 엔드포인트가 확인된다. 맨끝에는 가로로? 되어 있는 stream name이 있을 것

    - 그래서 이제 외부에서 수집용 데이터를 받을 떄는 이 엔드포인트를 통해서 받으면 되고
    - 이 stream name이라는 것은 data stream에서 하나 생성한 그 이름을 넣어주면 된다.

    ![2-2-21](https://user-images.githubusercontent.com/86764734/161564387-1bb6d76e-b629-4860-8192-fd3b2a526386.png)

- 테스트 진행

- 제공된 스크립에 엔드포인트 카피해서 붙여넣기

- 그 다음에 우리가 할 작업은? data stream을 만드는 것

#### 5. kinesis

- data-stream

![2-2-22](https://user-images.githubusercontent.com/86764734/161564428-4ca7e10c-2595-4624-9cf2-2e9f3987d82a.png)

- data-stream생성

- data-stream 이름

![2-2-23](https://user-images.githubusercontent.com/86764734/161564496-9590ee4c-5f07-4055-b001-5c316fb34177.png)

- data-stream 용량

    - 온디멘드는 많은 데이터가 몰려왔을 때 사용, 우리는 프로비저닝

    - 데이타가 들어오는 지속성이나 그런것들에 따라서 차징이 되기 때문에 그런것을 비교해보고 둘 중에 하나 선택하면 될듯

        ![2-2-24](https://user-images.githubusercontent.com/86764734/161564530-35b30269-8191-4343-82bf-2e1fdb85b761.png)

- 그리고 data-stream생성 클릭


![2-2-25](https://user-images.githubusercontent.com/86764734/161564608-239414fd-9395-4121-afeb-9f5af793393d.png)

- producer와 consumer
    - 생산자: 구성할 때는 aws sdk나 kinesis producer를 통해서 데이터를 kinesis에다가 수집을 하면 되고
    - 소비자: 우리는 consumer를 해야한다 s3에다 저장하는 것 그 부분은 firehose를 통해서 한다.

    ![2-2-26](https://user-images.githubusercontent.com/86764734/161564641-a60cda6a-efe8-49c3-b0a3-ae72539da2c0.png)

- Firehose

    - 전송스트림으로 처리 클릭하면 바로  firehose와 연결된다

    ![2-2-27](https://user-images.githubusercontent.com/86764734/161564655-27976ccd-99df-46d4-96a4-dcb3992a9604.png)
    
    - source는 스트림

    ![2-2-28](https://user-images.githubusercontent.com/86764734/161564673-e8bf9113-e2c1-45f6-86d2-21f24e05d5f1.png)

    - destination은 s3

    ![2-2-29](https://user-images.githubusercontent.com/86764734/161564743-8b403151-5092-471e-815d-3e28191b48eb.png)

    - source setting

    ![2-2-30](https://user-images.githubusercontent.com/86764734/161564747-78031162-0edd-4b37-94b8-67c1889e67da.png)

    - delivery stream name

        - 똑같이 설정

        ![2-2-31](https://user-images.githubusercontent.com/86764734/161564753-c1c74d7b-acef-4ed9-903c-cc9690a3670f.png)
    
    - 나머지는 체크하지 말고
    
    - 버켓만 설정해주고 서브폴더를 만들어 주자    

    ![2-2-32](https://user-images.githubusercontent.com/86764734/161564846-f165d47b-ff28-4138-b070-6ebbd8e9286f.png)

   ![2-2-33](https://user-images.githubusercontent.com/86764734/161564853-839acecd-009e-4a2b-9a1e-d6315caddbf8.png)

    - 그리고 지금 kinesis는 두개, 그래서 각각에 대해서 발송을하고 발송이 정상적으로 됐는지 확인을 해보자.

    - 버퍼사이즈 → 너무 크면 늦게 떨어져서 최소로

    ![2-2-34](https://user-images.githubusercontent.com/86764734/161564861-784aa68e-efbb-4d3b-86a9-b6eab4a115f5.png)

    - create delivery stream

        - kinesis 서비스가 하나 만약에 외부서비스가 하나 오픈 된다고 하면 거기서 들어오는 데이터를 특정 s3버킷에다가 저장하는 작업을 진행 이러한 방법으로 구성을 해놓으면 신규서비스가 생성이되도 수집하는데 얼마 안걸리게 데이터를 수집할 수 있다.    

        - url에 class1이라고 고쳐주자

- 우리가 curl이라는 명령어를 통해서 테스트를 해봤다.

- cli로 이동

![2-2-35](https://user-images.githubusercontent.com/86764734/161564942-28bc0f20-f07f-4d3c-9507-03a262d083de.png)

- 발송을 해보자

    - 이렇게 시퀀스넘버가 떨어지면 정상적으로 api게이트 웨이가 데이터를 정상적으로 받았다는 뜻

    ![2-2-36](https://user-images.githubusercontent.com/86764734/161564948-aa7a3903-7aa7-40ef-8ed8-83c3807d7caa.png)

- 그리고 하나는 class니까 이것도 같이 확인

    - 지금 하나의 url에 엔트포인트를 가지고 여러 kinesis로나눠서 발송할 수 있다.

    ![2-2-37](https://user-images.githubusercontent.com/86764734/161564955-6458b331-5ad0-408b-9cb7-954db137bc25.png)

- msa라고 한 이유는 그 중에서 어떤 스트림이 이상이 생겨도 데이터를 처리할 수 있기 때문에 그렇게 붙였고 사실 가장 중요한 포인트는 url을 통해서 우리가 aws안에 kinesis에 리소스를 핸들링해서 그 리소스에 데이터를 넣어줄 수 있다는 것. 그 점을 유의해서 넣어주면 되고 이게 나중에 정상적으로 운영을하거나 하면 url자체를 회사에서 쓰는 url로 바꾼 다음에 뒤에만 이제 kinesis를 하나 생성하고 변경해주면 쉽게 확장이 가능할 것이라고 보인다.

- 그럼 s3에 쌓였는지 확인해보자

    - class1이라는 서브폴터 확인 가능 클릭해서 들어가면    

    ![2-2-38](https://user-images.githubusercontent.com/86764734/161565038-7bbe3fdd-ed82-4980-91eb-e78b268e157d.png)

    - 연도/월/일/시 로 들어가면 로그 파일 하나가 생성된것을 확인 할 수 있다. 

   ![2-2-39](https://user-images.githubusercontent.com/86764734/161565049-d3b68a7d-723e-4362-b944-7c0a9ee594c1.png)

- 이렇게 확인한 후에 서비스쪽에서 들어오는 웹풋방식이라고 하는데, 그쪽에서 발생된 이벤트를 우리한테 패스시켜주는 방식이다. 그런 방식으로 하는 그런 서비스가 보통 외부서비스인 경우에는 많이 있기 때문에 데이터 자체를 내제화할 때는 그런 방식으로 하면 된다.

- 이렇게 하면 kinesis stream별로 데이터를 쉽게 구성할 수 있다.  

![2-2-40](https://user-images.githubusercontent.com/86764734/161565062-3b412cf8-1efb-4fbf-85ea-11975e8d8cef.png)

보통 이렇게 파이프라인을 만들어놓으면 그거를 계속 개선하는 작업을 하는데, 이런 방식으로 개선을 하면 나중에 운영을하거나 아니면 확장할 때 가장 편하게 사용할 수 있다. 